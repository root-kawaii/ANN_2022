
# We tried

1D_CNN
Bi-LSTM best so far
LSTM
GRU
RESNET

I also tried to do a mix between 1D and BILSTM but didn't work very well

# TODO


Ensamble, train many models and ensamble (pick best model for each class)
Categorical Accuracy
#ResNet, residuals 
#GRU (another RNN)
#MinMax scaling and similar things
Normalization on DATASET
Data augmentation 
Surely much more but also considering we have less days

# RESULTS

So far the results oscillate between 0.55 and 0.67 rouhly.
People seem to be getting slightly more I am not sure using what.
Paolo said normalization doesnt boost that much BUT WE NEED STUFF TO DISCUSS FOR THE REPORT
SO LETS DO IT !

# PERSONAL REMARKS

I really believe sonny boys it is one for the ages - Joahn Sebastian Bach